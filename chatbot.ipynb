{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chatbot - NLP and Deep Learning**\n",
    "\n",
    "For this project, we will use the PyTorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Theory and NLP concepts\n",
    "\n",
    "We will talk about stemming, tokenization, bag of words.\n",
    "\n",
    "First, we put all words (of each patterns) into an array.\n",
    "\n",
    "- **Bag of words :** For each different pattern, we create an array w/ the same size as the all words array. If this word is included into the all words array, we put a 1 at his position, 0 otherwise.\n",
    "- **Tokenization :** Splitting string into meaningful units (e.g. words, punctuation characters, numbers)\n",
    "- **Stemming :** Generate the root form of the words. It is an heuristic that chops of the ends off of words. \n",
    "\n",
    "### **Whole NLP pre-processing pipeline :** \n",
    "\n",
    "At the beginning, we have the Whole sentence, then we tokenize it. We lower all the words, then we stem the words. We then exclude punctuation characters. And based on this array, we calculate the bag of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. PyTorch model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Save and load model and implement the chat"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
